import os
import json
import math
from typing import List, Dict, Any, Optional

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from reco import recommend_rooms

from dotenv import load_dotenv
from google import genai
from google.genai import types

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì„¤ì • ë° í•˜ë“œì½”ë”© ë°ì´í„°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ENV_PATH = os.path.join(BASE_DIR, ".env")

print("ENV PATH:", ENV_PATH)

load_dotenv(ENV_PATH)

MY_GEMINI_API_KEY = os.getenv("MY_GEMINI_API_KEY")
print("Loaded MY_GEMINI_API_KEY:", MY_GEMINI_API_KEY)

if not MY_GEMINI_API_KEY:
    raise ValueError("âŒ MY_GEMINI_API_KEY is missing. Check your .env file!")
# -----------------------------------------------------

app = FastAPI(title="AI Space Recommendation API")
client = genai.Client(api_key=MY_GEMINI_API_KEY)

# ëª¨ë¸ ë¡œë“œ
model = joblib.load("crowd_classifier.pkl")

top_features = [
    'mfcc_9_mean', 'mfcc_7_mean', 'zcr', 'band0_300',
    'numberOfHuman', 'speech_noise_ratio', 'mfcc_3_mean',
    'mfcc_14_mean', 'mfcc_8_mean', 'centroid', 'bleNum'
]

# ì‚¬ëŒ ìˆ˜ ê°ì§€ í•¨ìˆ˜
def count_people(image_path):
    # YOLOv8 ëª¨ë¸ ë¡œë“œ
    model = YOLO("yolov8n.pt")
    img = cv2.imread(image_path)

    if img is None:
        print(f"[WARNING] Cannot read: {image_path}")
        return 0

    results = model(img, verbose=False)
    boxes = results[0].boxes
    
    person_count = 0

    for box in boxes:
        cls = int(box.cls)
        if cls == 0:  # YOLOì˜ person í´ë˜ìŠ¤ ID = 0
            person_count += 1

    return person_count

# -----------------------------
# 1. ë°´ë“œ ì—ë„ˆì§€ ê³„ì‚°ìš© ë³´ì¡° í•¨ìˆ˜
# -----------------------------
def band_energy(signal, sr, low, high):
    fft = np.abs(np.fft.rfft(signal))
    freqs = np.fft.rfftfreq(len(signal), d=1.0/sr)
    idx = np.where((freqs >= low) & (freqs <= high))[0]
    return fft[idx].mean() if len(idx) > 0 else 0


# -----------------------------
# 2. SPL ê³„ì‚°
# -----------------------------
def calc_spl(signal):
    rms = np.sqrt(np.mean(signal ** 2))
    return 20 * np.log10(rms + 1e-7)


# -----------------------------
# 3. MFCC + ì¡ìŒ ë³´ì •
# -----------------------------
def extract_mfcc(signal, sr, n_mfcc=20):
    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=n_mfcc)
    return mfcc.mean(axis=1), mfcc.var(axis=1)


# -----------------------------
# 4. ì „ì²´ ì˜¤ë””ì˜¤ íŠ¹ì§• ì¶”ì¶œ
# -----------------------------
def extract_audio_features(path=r"C:\realthon_t6\vid1.wav", n_mfcc=20):
    signal, sr = librosa.load(path, sr=None)

    # 1) SPL
    spl = calc_spl(signal)

    # 2) MFCC mean + var
    mfcc_mean, mfcc_var = extract_mfcc(signal, sr, n_mfcc=n_mfcc)

    # 3) ZCR
    zcr = librosa.feature.zero_crossing_rate(y=signal).mean()

    # 4) Centroid
    centroid = librosa.feature.spectral_centroid(y=signal, sr=sr).mean()

    # 5) Band energies
    band0_300 = band_energy(signal, sr, 0, 300)
    band300_3000 = band_energy(signal, sr, 300, 3000)
    band3000_8000 = band_energy(signal, sr, 3000, 8000)

    band_ratio_speech = band300_3000 / (band0_300 + 1e-7)

    # ëª¨ë“  feature í‰íƒ„í™”í•´ì„œ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ í•©ì¹¨
    features = {
        "spl": spl,
        "zcr": zcr,
        "centroid": centroid,
        "band0_300": band0_300,
        "band300_3000": band300_3000,
        "band3000_8000": band3000_8000,
        "speech_noise_ratio": band_ratio_speech,
    }

    # MFCC ì¶”ê°€
    for i, v in enumerate(mfcc_mean):
        features[f"mfcc_{i}_mean"] = v
    for i, v in enumerate(mfcc_var):
        features[f"mfcc_{i}_var"] = v

    return features 

def build_features(img_path, ble_raw, audio_path):
    img_count = count_people(img_path)
    ble_feats = ble_raw
    audio_feats = extract_audio_features(audio_path)

    row = {
        "numberOfHuman": img_count,
        "bleNum": ble_feats,
        **audio_feats
    }
    return row 

def predict_crowd(ID, img_path, ble_raw, audio_path):
    """
    feature_dict ì˜ˆì‹œ:
    {
       "mfcc_9_mean": -132.1,
       "mfcc_7_mean": 22.3,
       "zcr": 0.01,
       "band0_300": 47.1,
       "numberOfHuman": 14,
       "speech_noise_ratio": 0.22,
       "mfcc_3_mean": 30.4,
       "mfcc_14_mean": 4.12,
       "mfcc_8_mean": -2.11,
       "centroid": 1750.2,
       "bleNum": 83
    }
    """
    feature_dict = build_features(img_path, ble_raw, audio_path)
    row = {f: feature_dict[f] for f in top_features}

    df = pd.DataFrame([row])
    pred = model.predict(df)[0]            # class 0/1/2
    prob = model.predict_proba(df)[0]      # softmax í™•ë¥ 

    if pred == 0:
        result = round(6+random.uniform(-6, 6))
    elif pred == 1:
        result = round(19+random.uniform(-7, 7))
    else:
        result = round(32+random.uniform(-6, 6))
        
    return ID, result
    
# Spring Boot BEì—ì„œ í•˜ë“œì½”ë”©í•œ Space ë°ì´í„°ë¥¼ ë™ì¼í•˜ê²Œ ì ìš©
ALL_SPACE_DATA = [
    {
        "space_id": 201,
        "space_name": "ë§ˆíƒœì˜¤ê´€ 104í˜¸",
        "space_lat": 37.5526,
        "space_lon": 126.9392,
        "space_floor": 1,
        "space_capacity": 60,
        "quiet_score": 0.0,
        "talk_score": 1.0,
        "study_score": 1.0,
        "rest_score": 0.0,
    },
    {
        "space_id": 202,
        "space_name": "ë§ˆíƒœì˜¤ê´€ 101í˜¸",
        "space_lat": 37.5526,
        "space_lon": 126.9392,
        "space_floor": 1,
        "space_capacity": 20,
        "quiet_score": 1.0,
        "talk_score": 0.0,
        "study_score": 0.0,
        "rest_score": 1.0,
    },
    {
        "space_id": 203,
        "space_name": "ê¸ˆí˜¸ì•„ì‹œì•„ë‚˜ë°”ì˜¤ë¡œê²½ì˜ê´€ 1ì¸µ ë¼ìš´ì§€",
        "space_lat": 37.5524,
        "space_lon": 126.9388,
        "space_floor": 1,
        "space_capacity": 55,
        "quiet_score": 1.0,
        "talk_score": 0.0,
        "study_score": 1.0,
        "rest_score": 0.0,
    },
    {
        "space_id": 204,
        "space_name": "ì‚¼ì„±ê°€ë¸Œë¦¬ì—˜ê´€ 2ì¸µ ë¼ìš´ì§€",
        "space_lat": 37.5521,
        "space_lon": 126.9390,
        "space_floor": 2,
        "space_capacity": 18,
        "quiet_score": 1.0,
        "talk_score": 0.0,
        "study_score": 1.0,
        "rest_score": 0.0,
    },
    {
        "space_id": 205,
        "space_name": "ì •í•˜ìƒê´€ J ì—´ëŒì‹¤ ì• ì†ŒíŒŒ",
        "space_lat": 37.5504,
        "space_lon": 126.9430,
        "space_floor": 1,
        "space_capacity": 6,
        "quiet_score": 1.0,
        "talk_score": 0.0,
        "study_score": 0.0,
        "rest_score": 1.0,
    },
    {
        "space_id": 206,
        "space_name": "ê²Œí˜ë¥´íŠ¸ë‚¨ë•ìš°ê²½ì œê´€ ê³„ë‹¨1-2ì¸µ",
        "space_lat": 37.5504,
        "space_lon": 126.9398,
        "space_floor": 1,
        "space_capacity": 30,
        "quiet_score": 0.0,
        "talk_score": 1.0,
        "study_score": 0.0,
        "rest_score": 1.0,
    },
    {
        "space_id": 207,
        "space_name": "ë¡œìšœë¼ë„ì„œê´€ ê¿ˆê¾¸ëŠ”ìˆ²(ìˆ™ë©´ê³µê°„)",
        "space_lat": 37.5515,
        "space_lon": 126.9418,
        "space_floor": 1,
        "space_capacity": 15,
        "quiet_score": 1.0,
        "talk_score": 0.0,
        "study_score": 0.0,
        "rest_score": 1.0,
    },
    {
        "space_id": 208,
        "space_name": "ë‹¤ì‚°ê´€ 1ì¸µ",
        "space_lat": 37.5521,
        "space_lon": 126.9432,
        "space_floor": 1,
        "space_capacity": 40,
        "quiet_score": 1.0,
        "talk_score": 0.0,
        "study_score": 1.0,
        "rest_score": 0.0,
    },
    {
        "space_id": 209,
        "space_name": "ë² ë¥´í¬ë§ŒìŠ¤ìš°ì •ì› 2ì¸µ",
        "space_lat": 37.5505,
        "space_lon": 126.9390,
        "space_floor": 2,
        "space_capacity": 40,
        "quiet_score": 1.0,
        "talk_score": 0.0,
        "study_score": 1.0,
        "rest_score": 0.0,
    },
]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Pydantic ëª¨ë¸ ì •ì˜ (Spring Boot DTOì™€ ì¼ì¹˜)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# 2-1. AIëª¨ë¸1 í˜¸ì¶œ API Request (BE -> AI)
class AiPredictCountRequest(BaseModel):
    spaceId: int
    imagePath: str
    bluetooth: int
    audioFile: Optional[Any]

# 2-1. AIëª¨ë¸1 í˜¸ì¶œ API Response (AI -> BE)
class AiPredictCountResponse(BaseModel):
    spaceId: int
    predictCount: int

# 2-2. AIëª¨ë¸2 í˜¸ì¶œ API Request (BE -> AI) - List ë‚´ë¶€ ê°ì²´
class CandidateRoom(BaseModel):
    spaceId: int
    spaceName: str
    purposeScore: float
    distanceFeature: float
    predictCount: int
    capacity: int
    quiet_score: float
    talk_score: float
    study_score: float
    rest_score: float

# 2-2. AIëª¨ë¸2 í˜¸ì¶œ API Request (BE -> AI)
class AiRecommendationRequest(BaseModel):
    userId: int
    userText: str
    candidateRooms: List[CandidateRoom]

# 2-2. AIëª¨ë¸2 í˜¸ì¶œ API Response (AI -> BE) - Data List ë‚´ë¶€ ê°ì²´
class AiRecommendationResult(BaseModel):
    spaceId: int
    finalRecommendScore: float

# 2-2. AIëª¨ë¸2 í˜¸ì¶œ API Response (AI -> BE) - ì „ì²´ ì‘ë‹µ êµ¬ì¡°
class AiRecommendationResponse(BaseModel):
    status: str
    message: str
    data: List[AiRecommendationResult]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Gemini NLP ëª¨ë¸ (ëª©ì  ì ìˆ˜ ê³„ì‚°) í•¨ìˆ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

GEMINI_SCHEMA: Dict[str, Any] = {
    "type": "OBJECT",
    "properties": {
        "topSpaces": {
            "type": "ARRAY",
            "items": {
                "type": "OBJECT",
                "properties": {
                    "spaceId": {"type": "INTEGER"},
                    "purposeScore": {"type": "NUMBER"},
                },
                "required": ["spaceId", "purposeScore"],
            },
        },
        "placeFlag": {
            "type": "INTEGER",
            "description": "ì‹¤ì œ ì¥ì†Œ ì–¸ê¸‰ ì—¬ë¶€ (1/0)",
        },
        "placeName": {
            "type": "STRING",
            "description": "ì‚¬ìš©ìê°€ ë§í•œ ì‹¤ì œ ì¥ì†Œëª… (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)",
        },
    },
    "required": ["topSpaces", "placeFlag", "placeName"],
}


def _call_gemini(
    user_text: str,
    spaces: List[Dict[str, Any]],
    top_n: int,
) -> Dict[str, Any]:
    """Gemini API í˜¸ì¶œ"""
    spaces_for_llm = [
        {
            "spaceId": s["space_id"],
            "vector": [
                s["quiet_score"],
                s["talk_score"],
                s["study_score"],
                s["rest_score"],
            ],
        }
        for s in spaces
    ]
    spaces_json = json.dumps(spaces_for_llm, ensure_ascii=False)

    prompt = f"""
ë„ˆëŠ” ìº í¼ìŠ¤ ê³µê°„ ì¶”ì²œ ëª¨ë¸ì´ë‹¤.

- spaces: ê° ê³µê°„ì€ spaceIdì™€ vectorë¥¼ ê°€ì§„ë‹¤.
  vectorëŠ” ["ì¡°ìš©í•œ", "ëŒ€í™”í•˜ëŠ”", "ê³µë¶€í•˜ëŠ”", "íœ´ì‹í•˜ëŠ”"] ìˆœì„œì˜ ì ìˆ˜ì´ë‹¤.
- user_text: í•œêµ­ì–´ ë¬¸ì¥.

1. user_textë¥¼ ë¶„ì„í•´ì„œ ìœ„ 4ì°¨ì›ì— ëŒ€í•œ intent_vectorë¥¼ ë§ˆìŒì†ìœ¼ë¡œ ë§Œë“ ë‹¤.
2. ê° ê³µê°„ì˜ vectorì™€ intent_vector ì‚¬ì´ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•´ì„œ purposeScoreë¡œ ì‚¬ìš©í•œë‹¤.
3. purposeScoreë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•˜ì—¬ ìƒìœ„ {top_n}ê°œ ê³µê°„ë§Œ
   topSpaces ë°°ì—´ì— ë„£ëŠ”ë‹¤.
   ê° í•­ëª©ì€ {{ "spaceId", "purposeScore" }} ë§Œ í¬í•¨í•´ì•¼ í•œë‹¤.
4. user_text ì•ˆì— ì‹¤ì œ ì¥ì†Œëª…ì´ ì–¸ê¸‰ë˜ì—ˆëŠ”ì§€ ë³´ê³ ,
   - ì–¸ê¸‰ë˜ë©´ placeFlag = 1, placeName ì— ëŒ€í‘œ ì¥ì†Œëª…ì„ ë¬¸ìì—´ë¡œ ë„£ëŠ”ë‹¤.
   - ì•„ë‹ˆë©´ placeFlag = 0, placeName = "".

! ìœ„ë„/ê²½ë„(lat/lng)ëŠ” ì ˆëŒ€ ìƒì„±í•˜ì§€ ë§ˆë¼.
! ì¶œë ¥ì€ ë‚´ê°€ ì œê³µí•œ GEMINI_SCHEMAì— ì •í™•íˆ ë§ëŠ” ìˆœìˆ˜ JSONë§Œ í¬í•¨í•œë‹¤.
   ìì—°ì–´ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ì•ŠëŠ”ë‹¤.

spaces(JSON):
{spaces_json}

user_text:
\"\"\"{user_text}\"\"\"
"""

    resp = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=prompt,
        config=types.GenerateContentConfig(
            response_mime_type="application/json",
            response_schema=GEMINI_SCHEMA,
        ),
    )
    return json.loads(resp.text)


def run_nlp_model(
    user_text: str,
    spaces: List[Dict[str, Any]],
) -> Dict[int, float]:
    """NLP ëª¨ë¸ ì‹¤í–‰ í›„ purposeScore ë§µì„ ë°˜í™˜"""
    # spacesì˜ ê¸¸ì´ë§Œí¼ top_n ì„¤ì •í•˜ì—¬ ëª¨ë“  ê³µê°„ì— ëŒ€í•´ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ë„ë¡ ìš”ì²­
    gemini_res = _call_gemini(user_text, spaces, len(spaces))

    # spaceId: purposeScore ë§µ ìƒì„±
    purpose_score_map = {}
    for item in gemini_res.get("topSpaces", []):
        purpose_score_map[item["spaceId"]] = item["purposeScore"]

    return purpose_score_map

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# API ì—”ë“œí¬ì¸íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# 2-1. AIëª¨ë¸1 í˜¸ì¶œ API (ì¸ì›ìˆ˜ ê³„ì‚°)
@app.post("/ai/predict/count", response_model=AiPredictCountResponse)
async def predict_count_endpoint(request: AiPredictCountRequest):
    """
    AI ëª¨ë¸ 1 (í˜¼ì¡ë„ ì¸ì›ìˆ˜ ê³„ì‚°)
    """

    ID, result = predict_crowd(request.spaceId, request.imagePath, request.bluetooth, request.audioFile)
    # **AI ë¡œì§ ë”ë¯¸:** ìš”ì²­ëœ spaceIdë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„ì˜ì˜ ì¸ì›ìˆ˜ ë°˜í™˜
    dummy_count = 10 + math.ceil(math.sin(request.spaceId * 10) * 5)

    return AiPredictCountResponse(
        spaceId=request.spaceId,
        predictCount=int(result)
    )

# 2-2. AIëª¨ë¸2 í˜¸ì¶œ API (ìµœì¢… ì¶”ì²œ ì ìˆ˜ ê³„ì‚°)
@app.post("/api/v1/recommendation", response_model=AiRecommendationResponse)
async def recommend_endpoint(request: AiRecommendationRequest):
    """
    AI ëª¨ë¸ 2 (ìµœì¢… ì¶”ì²œ ì ìˆ˜ ê³„ì‚°) - NLP í†µí•©
    """
    if not MY_GEMINI_API_KEY:
        raise HTTPException(status_code=500, detail="Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    try:
        # 1. NLP ëª¨ë¸ ì‹¤í–‰: userTextë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë“  ê³µê°„ì˜ ëª©ì  ì ìˆ˜ë¥¼ ê³„ì‚°
        purpose_score_map = run_nlp_model(request.userText, ALL_SPACE_DATA)

        # 2. BEì—ì„œ ë°›ì€ í›„ë³´ ëª©ë¡ì— NLP ì ìˆ˜ë¥¼ ë®ì–´ì“°ê¸° (Overwrite)
        candidate_rooms_dicts = []
        for room in request.candidateRooms:
            # Pydantic ëª¨ë¸ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            room_dict = room.dict()
            space_id = room_dict["spaceId"]

            # NLPì—ì„œ ê³„ì‚°ëœ ëª©ì  ì ìˆ˜ë¡œ ë®ì–´ì“°ê¸°
            calculated_purpose_score = purpose_score_map.get(space_id, 0.0)
            room_dict["purposeScore"] = calculated_purpose_score

            candidate_rooms_dicts.append(room_dict)

        # 3. ì¶”ì²œ ëª¨ë¸(reco.py) í˜¸ì¶œ
        results = recommend_rooms(candidate_rooms_dicts)

        # 4. AiRecommendationResponse DTOì— ë§ê²Œ ê²°ê³¼ ë³€í™˜
        data = [
            AiRecommendationResult(
                spaceId=res["spaceId"],
                finalRecommendScore=res["finalRecommendScore"],
            )
            for res in results
        ]

        return AiRecommendationResponse(
            status="200",
            message="AI ì¶”ì²œ ì ìˆ˜ ê³„ì‚° ì™„ë£Œ (NLP í†µí•©)",
            data=data,
        )

    except Exception as e:
        # ë””ë²„ê¹…ì„ ìœ„í•´ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ìƒì„¸íˆ ì¶œë ¥
        raise HTTPException(status_code=500, detail=f"ì¶”ì²œ ëª¨ë¸ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy", "service": "AI Space Recommendation API"}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë©”ì¸ ì‹¤í–‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if __name__ == "__main__":
    import uvicorn

    # ğŸ’¡ í¬íŠ¸ 8001ë¡œ ì‹¤í–‰
    uvicorn.run(app, host="0.0.0.0", port=8001)




